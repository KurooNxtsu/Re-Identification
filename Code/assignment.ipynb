{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "951a5f7c",
   "metadata": {},
   "source": [
    "Implementation using frames and deepsort to perform identification and assigning labels to players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "video_path = r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\15sec_input_720p.mp4\"\n",
    "frames_folder = r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\frames\"\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_filename = os.path.join(frames_folder, f\"frame_{frame_count:04d}.jpg\")\n",
    "    cv2.imwrite(frame_filename, frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"Extracted {frame_count} frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "frames_folder = r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\frames\"\n",
    "video_output_path = r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\tracked_output.mp4\"\n",
    "yolo_model_path = r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\best.pt\"\n",
    "\n",
    "model = YOLO(yolo_model_path)\n",
    "model.verbose = False\n",
    "\n",
    "tracker = DeepSort(\n",
    "    max_age=8,\n",
    "    n_init=2,\n",
    "    nms_max_overlap=0.2,\n",
    "    max_cosine_distance=0.3,\n",
    "    nn_budget=None,\n",
    "    override_track_class=None,\n",
    "    embedder=\"mobilenet\",\n",
    "    half=True,\n",
    "    bgr=True,\n",
    "    embedder_gpu=True,\n",
    ")\n",
    "\n",
    "def random_color():\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "def get_sorted_frame_files(folder):\n",
    "    pattern = re.compile(r'frame_(\\d+)\\.jpg')\n",
    "    files = [f for f in os.listdir(folder) if pattern.match(f)]\n",
    "    return sorted(files, key=lambda x: int(pattern.match(x).group(1)))\n",
    "\n",
    "sorted_frames = get_sorted_frame_files(frames_folder)\n",
    "first_frame = cv2.imread(os.path.join(frames_folder, sorted_frames[0]))\n",
    "height, width = first_frame.shape[:2]\n",
    "\n",
    "writer = cv2.VideoWriter(video_output_path, cv2.VideoWriter_fourcc(*'mp4v'), 25.0, (width, height))\n",
    "track_colors = {}\n",
    "unique_ids = set()\n",
    "\n",
    "for idx, fname in enumerate(sorted_frames):\n",
    "    path = os.path.join(frames_folder, fname)\n",
    "    frame = cv2.imread(path)\n",
    "    \n",
    "    results = model.predict(frame, conf=0.25, verbose=False)[0]\n",
    "    detections = results.boxes.xywh.cpu().tolist()\n",
    "    confidences = results.boxes.conf.cpu().tolist()\n",
    "\n",
    "    formatted = []\n",
    "    for (x, y, w, h), conf in zip(detections, confidences):\n",
    "        formatted.append(([x - w/2, y - h/2, w, h], conf, 0))\n",
    "\n",
    "    tracks = tracker.update_tracks(formatted, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        tid = track.track_id\n",
    "        x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "\n",
    "        if tid not in track_colors:\n",
    "            track_colors[tid] = random_color()\n",
    "        color = track_colors[tid]\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, f\"ID: {tid}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        unique_ids.add(tid)\n",
    "\n",
    "    cv2.putText(frame, f\"Frame: {idx+1}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(frame, f\"Unique IDs: {len(unique_ids)}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    writer.write(frame)\n",
    "\n",
    "writer.release()\n",
    "print(f\"Tracking complete. Saved to {video_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b3983",
   "metadata": {},
   "source": [
    "Implementation using DeepSort and Osnet for re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Load your trained YOLOv8 model\n",
    "yolo = YOLO(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\best.pt\")\n",
    "\n",
    "# Initialize DeepSORT with OSNet\n",
    "tracker = DeepSort(\n",
    "    max_age=30,\n",
    "    n_init=3,\n",
    "    max_cosine_distance=0.4,\n",
    "    nn_budget=None,\n",
    "    embedder=\"torchreid\",\n",
    "    embedder_model_name=\"osnet_x1_0\",\n",
    "    embedder_wts=r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\osnet_x1_0_msmt17.pt\",  # Make sure it's TorchReID format\n",
    "    half=True,\n",
    "    bgr=True,\n",
    ")\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\15sec_input_720p.mp4\")\n",
    "out = cv2.VideoWriter(\"output_deepsort.mp4\",\n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                      cap.get(cv2.CAP_PROP_FPS),\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo.predict(frame, conf=0.5)[0]\n",
    "    detections = []\n",
    "\n",
    "    # Collect player detections\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls)\n",
    "        if yolo.names[cls].lower() != \"player\":\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        detections.append(([x1, y1, w, h], conf, 'player'))\n",
    "\n",
    "    # DeepSORT tracking\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    ann = Annotator(frame)\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        x1, y1, w, h = map(int, track.to_tlwh())\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        ann.box_label([x1, y1, x2, y2], f\"player {track_id}\", color=(0, 255, 0))\n",
    "\n",
    "    out.write(ann.result())\n",
    "    cv2.imshow(\"DeepSORT + OSNet\", ann.result())\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b688c",
   "metadata": {},
   "source": [
    "Using StrongSort and OsNet for re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb00ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from boxmot.tracker_zoo import create_tracker\n",
    "from pathlib import Path\n",
    "\n",
    "# Load YOLOv8 model\n",
    "yolo = YOLO(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\best.pt\")\n",
    "\n",
    "# Create StrongSORT tracker\n",
    "tracker = create_tracker(\n",
    "    tracker_type=\"strongsort\",\n",
    "    tracker_config=Path(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\strongsort.yaml\"),\n",
    "    reid_weights=Path(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\osnet_x1_0_msmt17.pth\"),\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\15sec_input_720p.mp4\")\n",
    "out = cv2.VideoWriter(\"output_strongsort.mp4\",\n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                      cap.get(cv2.CAP_PROP_FPS),\n",
    "                      (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo.predict(frame, conf=0.3)[0]\n",
    "    dets = []\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls)\n",
    "        if yolo.names[cls].lower() != \"player\":\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(float, box.xyxy[0])\n",
    "        conf = float(box.conf)\n",
    "        cls_id = float(cls)\n",
    "        dets.append([x1, y1, x2, y2, conf, cls_id])\n",
    "\n",
    "    dets = np.array(dets) if dets else np.empty((0, 6))\n",
    "    tracks = tracker.update(dets, frame)\n",
    "\n",
    "    ann = Annotator(frame)\n",
    "    for trk in tracks:\n",
    "        x1, y1, x2, y2, tid = map(int, trk[:5])\n",
    "        ann.box_label([x1, y1, x2, y2], f\"player {tid}\", color=(0, 255, 0))\n",
    "\n",
    "    out.write(ann.result())\n",
    "    cv2.imshow(\"StrongSORT\", ann.result())\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75faae",
   "metadata": {},
   "source": [
    "Using BotSort and Osnet for re-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "from boxmot.tracker_zoo import create_tracker\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup model & tracker\n",
    "yolo = YOLO(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\best.pt\")  # your trained model with \"player\" class\n",
    "tracker = create_tracker(\n",
    "    tracker_type=\"botsort\",\n",
    "    tracker_config=Path(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\botsort.yaml\"),\n",
    "    reid_weights=Path(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\osnet_x1_0)msmt17.pt\"),  # downloaded ReID file\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")\n",
    "\n",
    "# Video IO\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\nitis\\OneDrive\\Documents\\AMV\\Research\\15sec_input_720p.mp4\")\n",
    "out = cv2.VideoWriter(\"output_botsort_osnet.mp4\",\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "    cap.get(cv2.CAP_PROP_FPS),\n",
    "    (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo.predict(frame, conf=0.5)[0]\n",
    "    dets = []\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls)\n",
    "        if yolo.names[cls].lower() != \"player\":\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(float, box.xyxy[0])  # box.xyxy is likely a tensor of shape (1,4)\n",
    "        conf = float(box.conf)\n",
    "        cls_id = float(cls)  # or int(cls) if your tracker wants it as int\n",
    "        dets.append([x1, y1, x2, y2, conf, cls_id])\n",
    "\n",
    "    dets = np.array(dets) if dets else np.empty((0, 5))\n",
    "    tracks = tracker.update(dets, frame)\n",
    "\n",
    "\n",
    "\n",
    "    ann = Annotator(frame)\n",
    "    for trk in tracks:\n",
    "        x1, y1, x2, y2, tid = map(int, trk[:5])\n",
    "        ann.box_label([x1, y1, x2, y2], f\"player {tid}\", color=(0,255,0))\n",
    "\n",
    "    out.write(ann.result())\n",
    "    cv2.imshow(\"BoT‑SORT + OSNet\", ann.result())\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
